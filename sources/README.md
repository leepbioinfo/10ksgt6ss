# Source README

## Overview

This directory contains all the **Python** scripts used for the analyses in this project.  
Each file generates one or more figures, loads a dataset or performs some analysis.

## Required datasets

To be able to reproduce the results available in this repository, input datasets should be retrieved from three different sources:

1. This repository's [data](../data) directory.
2. The [Zenodo repository](https://zenodo.org/records/16358274) associated with this work, includes some very large files used by the script `genomes.py` (see below):
	1. 10ksgt6ss-3.zip: latest copy of our GitHub repository.
	2. merge2.tsv.gz: 10KSGs genome annotations in a tabular format.
	3. ssg.tsv: comma-separated table of sequence similarity groups and protein domain architectures for putative T6SS components and nearby genes.
4. The genome assemblies from BioProjects PRJEB35182 and PRJEB47910, available at [NCBI](https://www.ncbi.nlm.nih.gov/) website.

## Source Structure

- Code that requires changing file paths and/or download of publicily available data
  1. `step1.sh`: parse GFF files and run MMseqs2 to generate merged2.tsv, merged2.faa, merged2.c100i100.tsv and merged2.c100i100.fa.
  2. `step2.sh`: run HMMscan to annotate the proteomes and HMMsearch to identify putative homologs of T6SS components. Generates [t6ss.acc](../data/t6ss.acc).
  3. `step3.py`: load and merge `step1.sh` and `step2.sh` results. Generates the file ssg.tsv that is available in our Zenodo repository.
  4. `step4.py`: load the genome features table and merges it with MMseqs2 protein clusters and domain annotations.
  5. `step5.py`: define genomic sites by selecting up to 10 genes upstream and downstream of the identified T6SS components. This action is performed after removal of false positive hits of the T6SSiii_tssH model, which retrieves too many non-T6SS proteins.
  6. `step6.py`: process genomic sites using Jaccard's distance and the Louvain community detection algorithm.
  7. `step7.py`: build a preliminary set of putative new toxins by processing C-terminal unknown regions in proteins of genomic sites that are associated by fusion or neighborhood to T6SS markers.
  8. `step8.sh`: run our new toxin models against the 10KSG proteomes.
  9. `step9.py`: prepare info.pkl and coord.pkl from HMMsearch results generated by `step8.sh`. These files are used to generate Table EV1.
  
Note that the file `working_dfs.py` is a module whose function is to merge manually curated annotations with dataframes generated automatically by our pipeline (see above). These mergedi, curated dataframes encompass all data needed for figure generation and statistical analyses.

- Code that can be executed as soon as [the environment is setup](../README.md)
  - `fig_<figure number/item>.py`: Scripts used to generate the figures for the final manuscript. In the manuscript, some figures may have been edited with image software to enhance their quality and add other informative elements.

## Notes

- All code for the figures is organized so that each script can be run independently.
- **No code was modified after the results were finalized for publication.** These scripts represent exactly what was used to generate the figures and tables in the paper.

## Questions or Issues

If you encounter any problems reproducing the results or have questions about the code, please open an [issue](https://github.com/leepbioinfo/10ksgt6ss/issues).

---

*This repository is intended to maximize transparency and reproducibility of computational research. Feel free to reuse or adapt the scripts for your own work, citing this project where appropriate.*
